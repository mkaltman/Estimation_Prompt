{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5298a22-d770-47e8-982c-25eecc8e38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, GPT2Tokenizer,GPT2LMHeadModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pandas\n",
    "import zipfile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "# Download City Data\n",
    "url = 'https://simplemaps.com/static/data/world-cities/basic/simplemaps_worldcities_basicv1.77.zip'\n",
    "csv_file_name = 'worldcities.csv'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "        if csv_file_name in z.namelist():\n",
    "            with z.open(csv_file_name) as csv_file:\n",
    "                df = pd.read_csv(csv_file)\n",
    "        else:\n",
    "            print(\"CSV file not found in the ZIP archive.\")\n",
    "else:\n",
    "    print(\"Failed to download the ZIP file.\")\n",
    "\n",
    "# Filter And Sample World Cities Data\n",
    "df = df[(df.population>(10**5))]\n",
    "df.drop_duplicates(subset = [\"city\"],inplace = True, keep = False)\n",
    "cities = set(df.city.sample(n = 1000))\n",
    "\n",
    "# Calculates Token Length Adjusted Probability\n",
    "def sequence_probability(text):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    probs = torch.gather(probs, 2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    return(float(torch.exp(torch.mean(torch.log(probs)))))\n",
    "\n",
    "# Prepare And Evaluates Prompts\n",
    "text = \"{city} is a city that I've visited. It has a population of {population} people.\"\n",
    "temps = []\n",
    "temp_cities = {}\n",
    "pops = [10**5,5*10**5,10**6,2*10**6,5*10**6,10*10**6,25*10**6]\n",
    "for city in cities:\n",
    "    probs = []\n",
    "    for pop in pops:\n",
    "        tt = text.format(population = str(pop),city = city)\n",
    "        probs.append(sequence_probability(tt))\n",
    "    temp_cities[city] = probs\n",
    "frame = pd.DataFrame(temp_cities)\n",
    "\n",
    "#frame.to_csv(Stored_Research_Prompt_Frame.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b021a48-1082-4c7e-aed9-13c5bda1f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes And Reduce Dimensionality Of Probability Outputs\n",
    "frame_norm = frame/frame.sum(axis = \"rows\")\n",
    "X = frame_norm.sub(frame_norm.mean(axis = 1), axis = 0)\n",
    "\n",
    "# PCA To Isolate 1st Princomp\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X.T)\n",
    "first_princomp = pca.components_[0]\n",
    "\n",
    "# Takes Inner Product Of First Princomp And Data\n",
    "# A Monotonically Increasing Array Also Works Fairly Well\n",
    "# first_princomp = np.Array([0,1,2,3,4,5,6])\n",
    "\n",
    "inner_products = {}\n",
    "for column in X.columns:\n",
    "    inner_products[column] = np.dot(first_princomp, X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2e712-a589-46c2-b9ed-316482201eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run And Evaluate Regression\n",
    "\n",
    "# Prep Data\n",
    "df.loc[:,\"Guess\"] = df.city.map(inner_products).values\n",
    "df = df[~df.Guess.isna()]\n",
    "df.set_index(\"city\",inplace = True)\n",
    "df.sort_index(inplace = True)\n",
    "y = np.log(df.population)\n",
    "X = pd.DataFrame(df.Guess)\n",
    "\n",
    "# Run And Cross Validate\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=4, scoring='r2')\n",
    "r2 = np.mean(scores)\n",
    "print(\"Mean R2:\", r2)\n",
    "print(\"Individual Scores:\")\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
